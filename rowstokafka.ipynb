from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, StringType, FloatType, TimestampType
from pyspark.sql.functions import to_json, struct, col
from random import randint, choice
import datetime

 # TODO: Ensure this is correct
scala_version = '2.12' 
spark_version = '3.4.1'
csv_path = 's3a://jsifontes-cdp-data-east1/axo-spark-test/zeppelin/notebook/data.csv'
kafka_broker = 'axo-kafka-test-corebroker2.jsifonte.a465-9q4k.cloudera.site:9093, axo-kafka-test-corebroker1.jsifonte.a465-9q4k.cloudera.site:9093, axo-kafka-test-corebroker0.jsifonte.a465-9q4k.cloudera.site:9093'
kafka_user = 'jsifontes'
kafka_pass = '1QAZ2wsx.'
kafka_topic = 'axo-test-spark'
truststore_path = '/var/lib/cloudera-scm-agent/agent-cert/cm-auto-global_truststore.jks'
truststore_pass = 'XGYfrg376KH87dtPHb27Em700d'



packages = [
    f'org.apache.spark:spark-sql-kafka-0-10_{scala_version}:{spark_version}',
    'org.apache.kafka:kafka-clients:3.2.0'
]
spark = SparkSession.builder\
   .master("local")\
   .appName("certification-axo-spark-kafka")\
   .config("spark.jars.packages", ",".join(packages))\
   .getOrCreate()
